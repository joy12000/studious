from http.server import BaseHTTPRequestHandler
import json
import os
import requests
import traceback
import google.generativeai as genai # Reintroduce Gemini API
import google.ai.generativelanguage as glm # For multimodal parts
import io # For image handling
from PIL import Image # For image handling

class handler(BaseHTTPRequestHandler):
    def do_POST(self):
        api_keys = [
            os.environ.get('OPENROUTER_API_KEY_PRIMARY'),
            os.environ.get('OPENROUTER_API_KEY_SECONDARY'),
            os.environ.get('OPENROUTER_API_KEY_TERTIARY'),
            os.environ.get('OPENROUTER_API_KEY_QUATERNARY'),
            os.environ.get('OPENROUTER_API_KEY_QUINARY'),
            os.environ.get('GEMINI_API_KEY_PRIMARY'), # Add Gemini API keys
            os.environ.get('GEMINI_API_KEY_SECONDARY'),
            os.environ.get('GEMINI_API_KEY_TERTIARY'),
            os.environ.get('GEMINI_API_KEY_QUATERNARY')
        ]
        valid_keys = [key for key in api_keys if key]

        if not valid_keys:
            return self.handle_error(ValueError("ì„¤ì •ëœ OpenRouter API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."), "API í‚¤ ì„¤ì • ì˜¤ë¥˜", 500)

        last_error = None
        last_error_text = ""

        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            body = json.loads(post_data.decode('utf-8'))
            history = body.get('history', [])
            note_context = body.get('noteContext', '')
            model_identifier = body.get('model', 'google/gemini-2.5-flash')
            use_gemini_direct = body.get('useGeminiDirect', False) # New flag

            if not history:
                raise ValueError("ëŒ€í™” ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

            # --- [í”„ë¡¬í”„íŠ¸ ê°•í™”] ---
            system_prompt_text = r"""
            ë‹¹ì‹ ì€ í•™ìƒì˜ í•™ìŠµì„ ë•ëŠ” ìœ ëŠ¥í•œ AI íŠœí„°ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ ê·œì¹™ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

            # ğŸ¨ ì¶œë ¥ ì„œì‹ ê·œì¹™ (â˜…â˜…â˜…â˜…â˜… ê°€ì¥ ì¤‘ìš”)
            ë‹¹ì‹ ì´ ìƒì„±í•˜ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” ì•„ë˜ ê·œì¹™ì„ **ë°˜ë“œì‹œ** ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
            
            1.  **ìˆ˜í•™ ìˆ˜ì‹ (LaTeX):** ëª¨ë“  ìˆ˜í•™ ê¸°í˜¸, ë³€ìˆ˜, ë°©ì •ì‹ì€ **ë°˜ë“œì‹œ** KaTeX ë¬¸ë²•ìœ¼ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
                -   ì¸ë¼ì¸ ìˆ˜ì‹: `$`ë¡œ ê°ìŒ‰ë‹ˆë‹¤. ì˜ˆ: `$\frac{dT}{dx} = f(x, T)$`
                -   ë¸”ë¡ ìˆ˜ì‹: `$$`ë¡œ ê°ìŒ‰ë‹ˆë‹¤. ì˜ˆ: `$$\mu = e^{\int P(x)dx}$$`
            
            2.  **ì½”ë“œ (Code Block):** ëª¨ë“  ì†ŒìŠ¤ ì½”ë“œëŠ” **ë°˜ë“œì‹œ** ì–¸ì–´ë¥¼ ëª…ì‹œí•œ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
                -   ì˜ˆì‹œ: ```python\nprint("Hello")\n```
            
            3.  **í•µì‹¬ ìš©ì–´ (Tooltip):** ì¤‘ìš”í•œ ì „ê³µ ìš©ì–´ëŠ” **ë°˜ë“œì‹œ** `<dfn>` íƒœê·¸ë¡œ ê°ì‹¸ ì„¤ëª…ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
                -   ì˜ˆì‹œ: `<dfn title="ìƒë¯¸ë¶„ ë°©ì •ì‹(Ordinary Differential Equation)ì€ í•˜ë‚˜ì˜ ë…ë¦½ ë³€ìˆ˜ì— ëŒ€í•œ í•¨ìˆ˜ì™€ ê·¸ ë„í•¨ìˆ˜ë“¤ì„ í¬í•¨í•˜ëŠ” ë°©ì •ì‹ì…ë‹ˆë‹¤.">ìƒë¯¸ë¶„ ë°©ì •ì‹ (ODE)</dfn>`

            # ğŸ–¼ï¸ ì ˆëŒ€ ê·œì¹™: ëª¨ë“  ì‹œê° ìë£ŒëŠ” ë°˜ë“œì‹œ ì§€ì •ëœ ì–¸ì–´ì˜ ì½”ë“œ ë¸”ë¡ ì•ˆì— í¬í•¨í•˜ì—¬ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ê·œì¹™ì€ ì„ íƒì´ ì•„ë‹Œ í•„ìˆ˜ì…ë‹ˆë‹¤. ì½”ë“œ ë¸”ë¡ ë°”ê¹¥ì— ìˆœìˆ˜í•œ JSONì´ë‚˜ ë‹¤ì´ì–´ê·¸ë¨ ì½”ë“œë¥¼ ì ˆëŒ€ë¡œ ì¶œë ¥í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ì´ ê·œì¹™ì„ ìœ„ë°˜í•œ ì¶œë ¥ì€ ì‹¤íŒ¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.

            Mermaid (mermaid): ìˆœì„œë„, íƒ€ì„ë¼ì¸, ê°„íŠ¸ ì°¨íŠ¸ ë“± ë‹¨ìˆœí•˜ê³  ì •í˜•í™”ëœ ë‹¤ì´ì–´ê·¸ë¨ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
- **ì¤„ë°”ê¿ˆ:** ë…¸ë“œ ì•ˆì—ì„œ ì¤„ì„ ë°”ê¾¸ë ¤ë©´ ë°˜ë“œì‹œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í°ë”°ì˜´í‘œ(`"`)ë¡œ ê°ì‹¸ê³  ì‹¤ì œ ì—”í„° í‚¤ë¡œ ì¤„ì„ ë‚˜ëˆ ì•¼ í•©ë‹ˆë‹¤. `<br>` íƒœê·¸ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
- **ìˆ˜ì‹ ì‚¬ìš© ê¸ˆì§€:** Mermaid ë…¸ë“œ ì•ˆì—ì„œëŠ” LaTeX ìˆ˜ì‹ì„ ë Œë”ë§í•  ìˆ˜ ì—†ìœ¼ë‹ˆ, ë³µì¡í•œ ìˆ˜ì‹ ëŒ€ì‹  `Î”P`ì™€ ê°™ì€ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë‚˜ ìœ ë‹ˆì½”ë“œ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
            
            ììœ  ì‹œê°í™” (visual): ë³µì¡í•œ ê°œë…, ë¹„êµ, êµ¬ì¡° ë“±ì„ ì„¤ëª…í•´ì•¼ í•  ë•Œ, ì•„ë˜ ê·œì¹™ì— ë”°ë¼ ê°€ìƒì˜ UI ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°ë¥¼ JSONìœ¼ë¡œ ì„¤ê³„í•˜ì—¬ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì½”ë“œ ë¸”ë¡ì˜ ì–¸ì–´ëŠ” **visual**ë¡œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.

            ### visual JSON ìƒì„± ê·œì¹™ (â˜…â˜…â˜…â˜…â˜… ë°˜ë“œì‹œ ì¤€ìˆ˜)
            1.  **í…ìŠ¤íŠ¸ ë‚´ìš©**: í…ìŠ¤íŠ¸ë¥¼ í‘œì‹œí•  ë•ŒëŠ” ë°˜ë“œì‹œ `props` ê°ì²´ ì•ˆì— `content` ì†ì„±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
                -   **ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:** `{ "type": "text", "props": { "content": "ë‚´ìš©" } }`
                -   **ì˜ëª»ëœ ì˜ˆì‹œ:** `{ "type": "text", "props": { "children": "ë‚´ìš©" } }`

            2.  **ìš”ì†Œ ì¤‘ì²©**: ë‹¤ë¥¸ ìš”ì†Œë¥¼ ìì‹ìœ¼ë¡œ í¬í•¨í•  ë•ŒëŠ” ë°˜ë“œì‹œ ìµœìƒìœ„ ë ˆë²¨ì˜ `children` ë°°ì—´ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
                -   **ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:** `{ "type": "box", "children": [ { "type": "text", ... } ] }`
                -   **ì˜ëª»ëœ ì˜ˆì‹œ:** `{ "type": "box", "props": { "children": [ ... ] } }`

            3.  **ìŠ¤íƒ€ì¼ë§**: ìŠ¤íƒ€ì¼ì€ `className`ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ CSS ì†ì„±ì„ ì§ì ‘ í¬í•¨í•˜ëŠ” ì¸ë¼ì¸ `style` ê°ì²´ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
                -   **ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:** `{ "props": { "style": { "color": "blue", "fontSize": "16px" } } }`
                -   **ì˜ëª»ëœ ì˜ˆì‹œ:** `{ "props": { "className": "text-blue-500 text-base" } }`


            # ğŸ’¬ ëŒ€í™” ê·œì¹™
            1.  **ëª…í™•ì„±:** í•™ìƒì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
            2.  **í›„ì† ì§ˆë¬¸:** ë‹µë³€ ë§ˆì§€ë§‰ì— í•™ìƒì˜ ì‚¬ê³ ë¥¼ í™•ì¥í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ í›„ì† ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.
            3.  **JSON ì¶œë ¥:** ìµœì¢… ê²°ê³¼ëŠ” ë°˜ë“œì‹œ `{"answer": "...", "followUp": ["...", "...", "..."]}` í˜•ì‹ì˜ JSON ê°ì²´ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

            """

            if note_context:
                system_prompt_text += f"""
                ---
                # ì°¸ê³  ìë£Œ
                ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ í˜„ì¬ ë³´ê³  ìˆëŠ” ë…¸íŠ¸ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

                {note_context}
                ---
                """
            
                        system_prompt = { "role": "system", "content": system_prompt_text}
                        messages = [{"role": "user" if msg['role'] == 'user' else "assistant", "content": msg['parts'][0]['text']} for msg in history]
            
                        if use_gemini_direct:
                            gemini_api_keys = [key for key in valid_keys if key and key.startswith('AIza')] # Assuming Gemini keys start with AIza
                            if not gemini_api_keys:
                                raise ValueError("ì„¤ì •ëœ Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            
                            for i, api_key in enumerate(gemini_api_keys):
                                try:
                                    print(f"INFO: Gemini Direct ëª¨ë¸ '{model_identifier}' / API í‚¤ #{i + 1} (ìœ¼)ë¡œ í˜¸ì¶œ ì‹œë„...")
                                    genai.configure(api_key=api_key)
                                    model = genai.GenerativeModel(model_identifier.replace('google/', '')) # Remove 'google/' prefix for direct call
                
                                    # Prepare contents for Gemini API
                                    gemini_messages = []
                                    for msg in messages:
                                        parts = []
                                        if 'parts' in msg and msg['parts']:
                                            for part in msg['parts']:
                                                if 'text' in part:
                                                    parts.append(part['text'])
                                                # Add handling for image/pdf parts if needed for direct Gemini
                                        gemini_messages.append({'role': msg['role'], 'parts': parts})
                                    
                                    # Add system prompt as first user message for Gemini
                                    gemini_messages.insert(0, {'role': 'user', 'parts': [system_prompt_text]})
                                    gemini_messages.insert(1, {'role': 'model', 'parts': ['ë„¤, ì•Œê² ìŠµë‹ˆë‹¤.']}) # Acknowledge system prompt
                
                                    # Convert history to Gemini format
                                    gemini_history = []
                                    for msg in gemini_messages:
                                        if msg['role'] == 'user':
                                            gemini_history.append({'role': 'user', 'parts': [{'text': p} for p in msg['parts']]})
                                        elif msg['role'] == 'assistant':
                                            gemini_history.append({'role': 'model', 'parts': [{'text': p} for p in msg['parts']]})
                
                                    # Ensure the last message is from the user for generate_content
                                    if gemini_history and gemini_history[-1]['role'] == 'model':
                                        # If the last message is from the model, we need to add a dummy user message
                                        # or re-evaluate the history construction. For now, let's assume
                                        # the frontend always sends the last message as user.
                                        pass # This case should ideally not happen with current frontend logic
                
                                    # Call Gemini API
                                    response = model.generate_content(gemini_history)
                                    full_response_content = response.text
                
                                    # Extract answer and follow-up from Gemini response
                                    try:
                                        parsed_content = json.loads(full_response_content)
                                        answer = parsed_content.get('answer', full_response_content)
                                        follow_up = parsed_content.get('followUp', [])
                                    except json.JSONDecodeError:
                                        answer = full_response_content
                                        follow_up = []
                
                                    self.send_response(200)
                                    self.send_header('Content-type', 'application/json; charset=utf-8')
                                    self.end_headers()
                                    self.wfile.write(json.dumps({'answer': answer, 'followUp': follow_up}, ensure_ascii=False).encode('utf-8'))
                                    return
                
                                except Exception as e:
                                    last_error = e
                                    print(f"WARN: Gemini Direct API í‚¤ #{i + 1} ì‚¬ìš© ì‹¤íŒ¨. ë‹¤ìŒ í‚¤ë¡œ í´ë°±í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
                                    continue
                            raise ConnectionError(f"ëª¨ë“  Gemini API í‚¤ë¡œ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error_text}") from last_error
                        else: # Use OpenRouter
                            openrouter_api_keys = [key for key in valid_keys if key and not key.startswith('AIza')] # Assuming OpenRouter keys don't start with AIza
                            if not openrouter_api_keys:
                                raise ValueError("ì„¤ì •ëœ OpenRouter API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                            for i, api_key in enumerate(openrouter_api_keys):
                                try:
                                    print(f"INFO: OpenRouter ëª¨ë¸ '{model_identifier}' / API í‚¤ #{i + 1} (ìœ¼)ë¡œ í˜¸ì¶œ ì‹œë„...")
                                    payload = {
                                        "model": model_identifier,
                                        "messages": [system_prompt] + messages,
                                        "stream": True
                                    }
                                    if model_identifier.startswith('google/'):
                                        payload["response_format"] = {"type": "json_object"}
                
                                    response = requests.post(
                                        url="https://openrouter.ai/api/v1/chat/completions",
                                        headers={
                                            "Authorization": f"Bearer {api_key}",
                                            "Content-Type": "application/json",
                                            "HTTP-Referer": "https://studious.app",
                                            "X-Title": "Studious"
                                        },
                                        json=payload,
                                        stream=True
                                    )
                                    response.raise_for_status()
                                    
                                    self.send_response(200)
                                    self.send_header('Content-type', 'text/event-stream; charset=utf-8')
                                    self.end_headers()
                
                                    full_response_content = ""
                                    for line in response.iter_lines():
                                        if line:
                                            decoded_line = line.decode('utf-8')
                                            if decoded_line.startswith('data: '):
                                                json_str = decoded_line[len('data: '):]
                                                if json_str.strip() == '[DONE]':
                                                    break
                                                try:
                                                    data = json.loads(json_str)
                                                    if 'choices' in data and data['choices']:
                                                        delta = data['choices'][0].get('delta', {})
                                                        content = delta.get('content')
                                                        if content:
                                                            full_response_content += content
                                                            self.wfile.write(f"data: {json.dumps({'token': content}, ensure_ascii=False)}\n\n".encode('utf-8'))
                                                            self.wfile.flush()
                                                except json.JSONDecodeError:
                                                    print(f"WARN: ìŠ¤íŠ¸ë¦¼ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON ìˆ˜ì‹ : {json_str}")
                                                    continue
                                    
                                    try:
                                        follow_up_prompt = {
                                            "role": "system",
                                            "content": f"ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸ê³¼ AIì˜ ì „ì²´ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒì˜ ì‚¬ê³ ë¥¼ í™•ì¥í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ í›„ì† ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”. ì „ì²´ ë‹µë³€: '{full_response_content}'. ë°˜ë“œì‹œ '{{\"followUp\": [\"...\", \"...\", \"...\"]}}' í˜•ì‹ì˜ JSON ê°ì²´ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤."
                                        }
                                        
                                        follow_up_payload = {
                                            "model": model_identifier,
                                            "messages": [system_prompt] + messages + [{"role": "assistant", "content": full_response_content}, follow_up_prompt],
                                            "response_format": {"type": "json_object"}
                                        }
                
                                        follow_up_response = requests.post(
                                            url="https://openrouter.ai/api/v1/chat/completions",
                                            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
                                            json=follow_up_payload,
                                            timeout=60
                                        )
                                        follow_up_response.raise_for_status()
                                        follow_up_data = follow_up_response.json()
                                        follow_up_content = follow_up_data['choices'][0]['message']['content']
                                        
                                        self.wfile.write(f"data: {follow_up_content}\n\n".encode('utf-8'))
                                        self.wfile.flush()
                
                                    except Exception as fu_e:
                                        print(f"WARN: í›„ì† ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {fu_e}")
                
                                    self.wfile.write('data: [DONE]\n\n'.encode('utf-8'))
                                    self.wfile.flush()
                                    return
                
                                except requests.exceptions.RequestException as e:
                                    last_error = e
                                    if e.response is not None:
                                        last_error_text = e.response.text
                                    print(f"WARN: API í‚¤ #{i + 1} ì‚¬ìš© ì‹¤íŒ¨. ë‹¤ìŒ í‚¤ë¡œ í´ë°±í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
                                    continue
                
                            raise ConnectionError(f"ëª¨ë“  OpenRouter API í‚¤ë¡œ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_error_text}") from last_error        except Exception as e:
            self.handle_error(e, "API ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    def handle_error(self, e, message="ì˜¤ë¥˜ ë°œìƒ", status_code=500):
        print(f"ERROR: {message}: {e}")
        traceback.print_exc()
        if not hasattr(self, '_headers_sent') or not self._headers_sent:
            try:
                self.send_response(status_code)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                error_details = {"error": message, "details": str(e)}
                self.wfile.write(json.dumps(error_details).encode('utf-8'))
            except Exception as write_error:
                print(f"FATAL: ì˜¤ë¥˜ ì‘ë‹µì„ ë³´ë‚´ëŠ” ì¤‘ ì¶”ê°€ ì˜¤ë¥˜ ë°œìƒ: {write_error}")