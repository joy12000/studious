from http.server import BaseHTTPRequestHandler
import json
import os
import requests
import traceback
import google.generativeai as genai
import google.generativeai

import io
from PIL import Image

class handler(BaseHTTPRequestHandler):
    def do_POST(self):
        # API í‚¤ ëª©ë¡ì„ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        api_keys = [
            os.environ.get('OPENROUTER_API_KEY_PRIMARY'),
            os.environ.get('OPENROUTER_API_KEY_SECONDARY'),
            os.environ.get('OPENROUTER_API_KEY_TERTIARY'),
            os.environ.get('OPENROUTER_API_KEY_QUATERNARY'),
            os.environ.get('OPENROUTER_API_KEY_QUINARY'),
            os.environ.get('GEMINI_API_KEY_PRIMARY'),
            os.environ.get('GEMINI_API_KEY_SECONDARY'),
            os.environ.get('GEMINI_API_KEY_TERTIARY'),
            os.environ.get('GEMINI_API_KEY_QUATERNARY')
        ]
        valid_keys = [key for key in api_keys if key]

        if not valid_keys:
            return self.handle_error(ValueError("ì„¤ì •ëœ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."), "API í‚¤ ì„¤ì • ì˜¤ë¥˜", 500)

        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            body = json.loads(post_data.decode('utf-8'))
            
            history = body.get('history', [])
            note_context = body.get('noteContext', '')
            model_identifier = body.get('model', 'gemini-2.5-flash')
            file_urls = body.get('fileUrls', [])

            if not history:
                raise ValueError("ëŒ€í™” ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

            # --- [í”„ë¡¬í”„íŠ¸ ê°•í™”] ---
            system_prompt_text = self.get_system_prompt(note_context)
            
            messages = self.prepare_messages(history)

            # --- [íŒŒì¼ ì²˜ë¦¬] ---
            image_parts = []
            if file_urls:
                for url in file_urls:
                    try:
                        response = requests.get(url)
                        response.raise_for_status()
                        content_type = response.headers.get('content-type')
                        if content_type and 'image' in content_type:
                            img = Image.open(io.BytesIO(response.content))
                            image_parts.append(img)
                    except Exception as e:
                        print(f"WARN: íŒŒì¼ URL ì²˜ë¦¬ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {e}")

            # API ê³µê¸‰ì ì„ íƒ ë° ì‹¤í–‰
            if model_identifier.startswith('gemini-'):
                self.execute_gemini_direct(model_identifier, messages, system_prompt_text, valid_keys, image_parts)
            else:
                # OpenRouterëŠ” í˜„ì¬ ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì„ ì´ í˜•ì‹ìœ¼ë¡œ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                self.execute_openrouter(model_identifier, messages, system_prompt_text, valid_keys)

        except Exception as e:
            self.handle_error(e, "API ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    def get_system_prompt(self, note_context):
        prompt = r"""
        ë‹¹ì‹ ì€ í•™ìƒì˜ í•™ìŠµì„ ë•ëŠ” ìœ ëŠ¥í•œ AI íŠœí„°ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ ê·œì¹™ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

        # ğŸ¨ ì¶œë ¥ ì„œì‹ ê·œì¹™ (â˜…â˜…â˜…â˜…â˜… ê°€ì¥ ì¤‘ìš”)
        ë‹¹ì‹ ì´ ìƒì„±í•˜ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” ì•„ë˜ ê·œì¹™ì„ **ë°˜ë“œì‹œ** ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
        1.  **ìˆ˜í•™ ìˆ˜ì‹ (LaTeX):** ëª¨ë“  ìˆ˜í•™ ê¸°í˜¸, ë³€ìˆ˜, ë°©ì •ì‹ì€ **ë°˜ë“œì‹œ** KaTeX ë¬¸ë²•ìœ¼ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤. (ì¸ë¼ì¸: `$`, ë¸”ë¡: `$$`)
        2.  **ì½”ë“œ (Code Block):** ëª¨ë“  ì†ŒìŠ¤ ì½”ë“œëŠ” **ë°˜ë“œì‹œ** ì–¸ì–´ë¥¼ ëª…ì‹œí•œ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: ```python\nprint("Hello")\n```)
        3.  **í•µì‹¬ ìš©ì–´ (Tooltip):** ì¤‘ìš”í•œ ì „ê³µ ìš©ì–´ëŠ” **ë°˜ë“œì‹œ** `<dfn>` íƒœê·¸ë¡œ ê°ì‹¸ ì„¤ëª…ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: `<dfn title="ì„¤ëª…">ìš©ì–´</dfn>`)

# ğŸ‘¨â€ğŸ« ë©”íƒ€-ì„¤ëª… ê·œì¹™ (ê·œì¹™ì— ëŒ€í•´ ì„¤ëª…í•  ë•Œì˜ ê·œì¹™)
ë‹¹ì‹ ì´ ìì‹ ì˜ ì¶œë ¥ ì„œì‹ ê·œì¹™ ìì²´ì— ëŒ€í•´ ì„¤ëª…í•´ì•¼ í•  ê²½ìš°, ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ìê°€ 'ì½”ë“œ ì˜ˆì‹œ'ì™€ 'ì‹¤ì œ ì‹¤í–‰ ê²°ê³¼'ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í˜¼ë€ì„ ë°©ì§€í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.

1.  **ì½”ë“œ ë¬¸ë²•ì€ ë°˜ë“œì‹œ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ:** íŠ¹ì • ì„œì‹ì˜ ë¬¸ë²•(Syntax)ì´ë‚˜ ì½”ë“œ ìì²´ë¥¼ ë³´ì—¬ì¤„ ë•ŒëŠ”, ë°˜ë“œì‹œ ì¸ë¼ì¸ ì½”ë“œ ë¸”ë¡(ë°±í‹± ` `)ì´ë‚˜ ì „ì²´ ì½”ë“œ ë¸”ë¡(```)ìœ¼ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•´ë‹¹ ì½”ë“œê°€ ë Œë”ë§ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³ , ë¬¸ì ê·¸ëŒ€ë¡œì˜ í…ìŠ¤íŠ¸ì„ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤.

        # ğŸ–¼ï¸ ì‹œê° ìë£Œ ê·œì¹™
        - Mermaid ë‹¤ì´ì–´ê·¸ë¨ì€ ë°˜ë“œì‹œ `mermaid` ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
        - `visual` JSON ë°ì´í„°ëŠ” ë°˜ë“œì‹œ `visual` ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.

        ### Mermaid (mermaid)
        - **ë”°ì˜´í‘œ ê·œì¹™:** ë…¸ë“œ ì´ë¦„, ë§í¬ í…ìŠ¤íŠ¸, subgraph ì œëª©ì— ì¤„ë°”ê¿ˆ, ê³µë°±, ë˜ëŠ” íŠ¹ìˆ˜ë¬¸ì `( ) ,`ê°€ í¬í•¨ë  ê²½ìš°, ë°˜ë“œì‹œ ì „ì²´ ë‚´ìš©ì„ í°ë”°ì˜´í‘œ(`"`)ë¡œ ê°ì‹¸ì•¼ í•©ë‹ˆë‹¤.
        - **ì¤„ë°”ê¿ˆ:** ë…¸ë“œ ì•ˆì—ì„œ ì¤„ì„ ë°”ê¾¸ë ¤ë©´ `<br>` íƒœê·¸ ëŒ€ì‹ , ë°˜ë“œì‹œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í°ë”°ì˜´í‘œ(`"`)ë¡œ ê°ì‹¸ê³  ì‹¤ì œ ì—”í„° í‚¤ë¡œ ì¤„ì„ ë‚˜ëˆ ì•¼ í•©ë‹ˆë‹¤.
        - **ìˆ˜ì‹ ì‚¬ìš© ê¸ˆì§€:** Mermaid ë…¸ë“œ ì•ˆì—ì„œëŠ” LaTeX ìˆ˜ì‹ì„ ë Œë”ë§í•  ìˆ˜ ì—†ìœ¼ë‹ˆ, `Î”P`ì™€ ê°™ì€ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë‚˜ ìœ ë‹ˆì½”ë“œ ê¸°í˜¸ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        
        ### Visual JSON (visual)
        - ë³µì¡í•œ ê°œë… ì‹œê°í™”. `props`ì— `content` ì‚¬ìš©, ìì‹ì€ `children` ë°°ì—´, ìŠ¤íƒ€ì¼ì€ ì¸ë¼ì¸ `style` ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        - **ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:**
        ```visual
        {
          "type": "box",
          "children": [ { "type": "text", "props": { "content": "ì˜ˆì‹œ" } } ]
        }
        ```

        # ğŸ“ ë…¸íŠ¸ ìˆ˜ì • ì œì•ˆ ê·œì¹™
        ë…¸íŠ¸ ë‚´ìš© ìˆ˜ì •ì„ ì œì•ˆí•  ê²½ìš°, **ì ˆëŒ€ë¡œ, ë°˜ë“œì‹œ** ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ê·œì¹™ì„ ì–´ê¸¸ ì‹œ, ì‘ë‹µì€ ì‹¤íŒ¨ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.
        ```suggestion
        ê¸°ì¡´ ë‚´ìš©
        ===>
        ìƒˆë¡œìš´ ë‚´ìš©
        ```

        ## ğŸ’¡ ìˆ˜ì • ì œì•ˆ ì˜ˆì‹œ
        ### ì‚¬ìš©ì ì§ˆë¬¸:
        "ë² ë¥´ëˆ„ì´ ë°©ì •ì‹ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜."
        ### ë…¸íŠ¸ ë‚´ìš©:
        "ë² ë¥´ëˆ„ì´ ë°©ì •ì‹ì€ ìœ ì²´ì˜ ì†ë„ì™€ ì••ë ¥ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤."
        ### AI ë‹µë³€ ì˜ˆì‹œ:
        "ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤! ë² ë¥´ëˆ„ì´ ë°©ì •ì‹ì€ ìœ ì²´ì˜ ì—ë„ˆì§€ê°€ ë³´ì¡´ëœë‹¤ëŠ” ì›ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. í˜„ì¬ ë…¸íŠ¸ì— ìˆëŠ” ë‚´ìš©ì„ ì¡°ê¸ˆ ë” ëª…í™•í•˜ê²Œ ë‹¤ë“¬ì–´ ë³¼ê¹Œìš”?
        ```suggestion
        ê¸°ì¡´ ë‚´ìš©
        ë² ë¥´ëˆ„ì´ ë°©ì •ì‹ì€ ìœ ì²´ì˜ ì†ë„ì™€ ì••ë ¥ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
        ===>
        ìƒˆë¡œìš´ ë‚´ìš©
        ë² ë¥´ëˆ„ì´ ë°©ì •ì‹ì€ ì ì„±ê³¼ ì••ì¶•ì„±ì´ ì—†ëŠ” ì´ìƒì ì¸ ìœ ì²´ê°€ ê·œì¹™ì ìœ¼ë¡œ íë¥¼ ë•Œ, ì†ë ¥ê³¼ ì••ë ¥, ìœ„ì¹˜ ì—ë„ˆì§€ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë²•ì¹™ì…ë‹ˆë‹¤.
        ```
        ìœ„ì™€ ê°™ì´ ìˆ˜ì •í•˜ë©´ ê°œë…ì„ ë” ì •í™•í•˜ê²Œ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë  ê±°ì˜ˆìš”."

        # ğŸ’¬ ëŒ€í™” ê·œì¹™
        1.  **ëª…í™•ì„±:** í•™ìƒì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  êµ¬ì¡°ì ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
        2.  **ë‹µë³€ í˜•ì‹:** ì ˆëŒ€ë¡œ JSONì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ë‹¤ë¥¸ ë¶€ê°€ ì •ë³´ë‚˜ í¬ì¥ ì—†ì´, ìˆœìˆ˜í•œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë‹µë³€ë§Œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
"""
        if note_context:
            prompt += f"\n---\n# ì°¸ê³  ìë£Œ\nì•„ë˜ëŠ” ì‚¬ìš©ìê°€ í˜„ì¬ ë³´ê³  ìˆëŠ” ë…¸íŠ¸ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n{note_context}\n---"
        return prompt

    def prepare_messages(self, history):
        messages = []
        for msg in history:
            role = 'user' if msg['role'] == 'user' else 'assistant'
            # ì´ì „ ëŒ€í™”ì—ì„œ ë´‡ì˜ ë‹µë³€ì— í¬í•¨ëœ í›„ì† ì§ˆë¬¸ì€ ì œì™¸í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
            content = msg.get('text', msg.get('parts', [{}])[0].get('text', ''))
            messages.append({"role": role, "content": content})
        return messages

    def execute_gemini_direct(self, model_identifier, messages, system_prompt_text, valid_keys, image_parts=[]):
        gemini_api_keys = [key for key in valid_keys if key and key.startswith('AIza')]
        if not gemini_api_keys:
            raise ValueError("ì„¤ì •ëœ Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

        last_error = None
        for i, api_key in enumerate(gemini_api_keys):
            try:
                print(f"INFO: Gemini Direct ëª¨ë¸ '{model_identifier}' / API í‚¤ #{i + 1} í˜¸ì¶œ ì‹œë„...")
                genai.configure(api_key=api_key)
                
                clean_model_id = model_identifier.replace('google/', '')
                model = genai.GenerativeModel(clean_model_id)

                gemini_messages = [
                    {'role': 'user', 'parts': [system_prompt_text]},
                    {'role': 'model', 'parts': ['ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ê·œì¹™ì„ ëª¨ë‘ í™•ì¸í–ˆìœ¼ë©°, ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤.']}
                ] + self.convert_to_gemini_format(messages)

                # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì— ì´ë¯¸ì§€ ì¶”ê°€
                if image_parts and gemini_messages:
                    last_message = gemini_messages[-1]
                    if last_message['role'] == 'user':
                        # í…ìŠ¤íŠ¸ íŒŒíŠ¸ì™€ ì´ë¯¸ì§€ íŒŒíŠ¸ë¥¼ ê²°í•©
                        text_part = last_message['parts'][0] # ê¸°ì¡´ í…ìŠ¤íŠ¸ íŒŒíŠ¸
                        last_message['parts'] = [text_part] + image_parts

                response = model.generate_content(
                    gemini_messages,
                    stream=True
                )
                
                self.stream_json_response(response)
                return
            except Exception as e:
                last_error = e
                print(f"WARN: Gemini Direct API í‚¤ #{i + 1} ì‚¬ìš© ì‹¤íŒ¨. ë‹¤ìŒ í‚¤ë¡œ í´ë°±í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
        raise ConnectionError(f"ëª¨ë“  Gemini API í‚¤ë¡œ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from last_error

    def convert_to_gemini_format(self, messages):
        gemini_history = []
        for msg in messages:
            role = 'model' if msg['role'] == 'assistant' else 'user'
            gemini_history.append({'role': role, 'parts': [{'text': msg['content']}]})
        return gemini_history

    def execute_openrouter(self, model_identifier, messages, system_prompt_text, valid_keys):
        openrouter_api_keys = [key for key in valid_keys if not (key and key.startswith('AIza'))]
        if not openrouter_api_keys:
            raise ValueError("ì„¤ì •ëœ OpenRouter API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

        last_error = None
        for i, api_key in enumerate(openrouter_api_keys):
            try:
                print(f"INFO: OpenRouter ëª¨ë¸ '{model_identifier}' / API í‚¤ #{i + 1} í˜¸ì¶œ ì‹œë„...")
                payload = {
                    "model": model_identifier,
                    "messages": [{"role": "system", "content": system_prompt_text}] + messages,
                    "stream": True
                }

                response = requests.post(
                    url="https://openrouter.ai/api/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json",
                        "HTTP-Referer": "https://studious.app",
                        "X-Title": "Studious"
                    },
                    json=payload,
                    stream=True
                )
                response.raise_for_status()
                
                self.stream_openrouter_response(response)
                return
            except requests.exceptions.RequestException as e:
                last_error = e
                print(f"WARN: API í‚¤ #{i + 1} ì‚¬ìš© ì‹¤íŒ¨. ë‹¤ìŒ í‚¤ë¡œ í´ë°±í•©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
        raise ConnectionError(f"ëª¨ë“  OpenRouter API í‚¤ë¡œ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from last_error

    def stream_json_response(self, response_iterator):
        self.send_response(200)
        self.send_header('Content-type', 'text/event-stream; charset=utf-8')
        self.end_headers()
        
        try:
            for chunk in response_iterator:
                if chunk.text:
                    token_json = json.dumps({"type": "token", "content": chunk.text})
                    self.wfile.write(f"data: {token_json}\n\n".encode('utf-8'))
                    self.wfile.flush()
                if hasattr(chunk, 'info') and hasattr(chunk.info, 'thought_summary') and chunk.info.thought_summary:
                    thought_json = json.dumps({"type": "thought", "content": chunk.info.thought_summary})
                    self.wfile.write(f"data: {thought_json}\n\n".encode('utf-8'))
                    self.wfile.flush()
        except Exception as e:
            print(f"ERROR: ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            error_json = json.dumps({"error": "ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "details": str(e)})
            self.wfile.write(f"data: {error_json}\n\n".encode('utf-8'))
            self.wfile.flush()

        # ìŠ¤íŠ¸ë¦¼ì˜ ëì„ ì•Œë¦¬ëŠ” [DONE] ë©”ì‹œì§€ ì „ì†¡
        self.wfile.write('data: [DONE]\n\n'.encode('utf-8'))
        self.wfile.flush()

    def stream_openrouter_response(self, response):
        self.send_response(200)
        self.send_header('Content-type', 'text/event-stream; charset=utf-8')
        self.end_headers()

        try:
            for line in response.iter_lines():
                if line:
                    decoded_line = line.decode('utf-8')
                    if decoded_line.startswith('data: '):
                        json_str = decoded_line[len('data: '):].strip()
                        if json_str == '[DONE]':
                            break
                        if not json_str:
                            continue
                        
                        try:
                            data = json.loads(json_str)
                            if 'choices' in data and data['choices']:
                                delta = data['choices'][0].get('delta', {})
                                content = delta.get('content')
                                if content:
                                    # í† í°ì„ í¬í•¨í•œ JSON ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ì „ì†¡
                                    token_json = json.dumps({"token": content})
                                    self.wfile.write(f"data: {token_json}\n\n".encode('utf-8'))
                                    self.wfile.flush()
                        except json.JSONDecodeError:
                            print(f"WARN: OpenRouter ìŠ¤íŠ¸ë¦¼ì˜ JSON íŒŒì‹± ì‹¤íŒ¨: {json_str}")
                            continue
        except Exception as e:
            print(f"ERROR: OpenRouter ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            error_json = json.dumps({"error": "ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "details": str(e)})
            self.wfile.write(f"data: {error_json}\n\n".encode('utf-8'))
            self.wfile.flush()

        self.wfile.write('data: [DONE]\n\n'.encode('utf-8'))
        self.wfile.flush()

    def handle_error(self, e, message="ì˜¤ë¥˜ ë°œìƒ", status_code=500):
        print(f"ERROR: {message}: {e}")
        traceback.print_exc()
        if not getattr(self, '_headers_sent', False):
            self.send_response(status_code)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
        error_details = {"error": message, "details": str(e)}
        self.wfile.write(json.dumps(error_details).encode('utf-8'))
